---
layout: post
title: "[통계기초 정리] 개인적인 통계 방법론 복습 (1. 용어와 확률분포)"
categories:
  - 통계기초
tags:
  -  basic statistics
  - statistical distribution
  - random variable
  - sample space
comment: true
---


기초 지식이지만 모든 고급분석의 근반이 되기에, 기초를 탄탄히 하고자 한번의 수업수강과 한번의 청강, 한번의 도강(...)까지 했다. 그치만 매번 공부하고 공부해도 까먹는 통계 기초. 늘 책찾고 헤매는 것이 힘들어서 한번에 정리해보았다.

### 용어의 정의

정의란? : 토씨하나 틀리지 않고, 그대로 외우는것(구어체도 좀 있으니 유도리 있게 접근하자)

- **통계적 실험(random experiment)** : 자료의 수집과 해석이 '확률'에 바탕을 두는 실험. (우리가 관찰하는 모든것은 통계적 실험이라 할 수 있다. )ex)동전던지기.H,T
- **random** : 딱히 정의가 내려지지 않고 사용되어 버렸다. 이는 확률이 이론이 아닌 실생활에서(정확히는 도박에서) 자연스럽게 파생되었기 때문.
  - 교수님 생각의 random : 결과를 보기 전엔 그 누구도 정확하게 예측할 수 없는 것.


- **표본공간(Sample Space)** :  통계적 실험의 '**모든**' '**가능한**' 결과들의 집합. $$\Omega$$

  - ex) 서로다른 동전 세입을 던졌을때의 결과
    - $$\Omega=\left\{ (H,H,H), (H,H,T)..(T,T,T) \right\}$$

  > 모든 사상들(표본공간의 부분집합)의 집합을 $$F$$로 따로 부르기도.
  >
  > $$F=\left\{\left\{\emptyset\right\}..\left\{\Omega\right\}\right\}$$등도 포함하기에 Sample Space와 같은개념이 아님.

- **사상(event)** : '표본공간의 부분집합' (우리가 흔히 생각하는 event의 의미랑 직결됨)

- **확률** : 이 역시 명확하게 **정의**내려져 있지는 않음. 다만, **확률의 3가지 공리**만이 정립되있다.

  - 처음엔 도박에서 나옴. '반복시행'이 가능한 것에 대해서 그 상대비율이 어디로 수렴하는지. 

  - 그러나 '반복시행'이 가능하지 않은 경우에도 확률을 쓰기 시작함. 그로 인해 생긴 확률의 **'공리적 정의'**.  (누구나 이해할 수 있는 성질 3개를 가지고 정의를 해보자)

  - 확률이란, 사상들의 집합 $$F$$에서  실수$$R$$로 가는, **함수**인데, 다음의 3가지 성질을 만족한다.

    - 1. $$0\le P(E)\le1, \forall E$$

      2. $$P(S)$$=1

      3. $$E_1,.,E_n$$이 서로 배반일때,

         $$P(\cup_{i=1}^nE_i)=\sum_{i=0}^nP(E_i)$$

- 확률 변수(random variable) : 사실 '**확률함수**'가 의미상 더 맞는데, 잘못 정착된것.

  정의역을 Sample Space에서 공역을 실수$$R$$로 가는 '**함수**'이다.

  > Sample space의 원소들(전체 혹은 일부)을 실수로 매핑하는 함수. ex)(H,H,H)->3, (H,H,T)->2 이런식으로.

  확률변수는 **항상**, 그에 따른 **확률분포**를 가지고 있다!

확률변수를 설명하실땐 이해를 위해서 인지 이산형을 기준으로 설명하심.

- **이산형 확률 변수** : 확률변수긴한데, 확률변수가 취할 수 있는 값의 개수가 infinite, or countably infinite일때. 즉 취할 수 있는 값 사이에 '**간격**'이 존재할때! (이 경우 확률분포표로 확률변수가 취할 수 있는 가능한 값과 그에따른 확률을 나열할 수 있다.)

- **연속형 확률변수** : 확률변수가 실수의 일부구간이나 모든 시룻에 대해 값을 취할때, 이를 연속형 확률변수라고 한다.

- **결합(Joint) 확률 분포** : Joint, 즉 확률변수가 2개 이상. 이산형에 대해, 취할 수 있는 모든 사상과 그에 대해 취할 확률을 나열한것.즉, '다변량 분포'이다.

  > 이 결합확률 분포를 하나의 확률변수만 남기고 intergral한게 marginal distribution. 즉, '결합확률을 안다는 것은 marginal도 안다는것!'
  >
  > ex)$$f_{X}(x)=\sum_{\forall y}f_{X,Y}(x,y)$$. 반대의 경우 성립하지 않는다. 왜? 뒤에 나올 covariance때문에.

- **독립** : X,Y가 독립이다 < = > $$f_{XY}(x,y)=f_{X}(x)f_Y(y),\forall (x,y)$$. 즉, 확률변수들의 결합확률 질량함수가 각각의 주변확률 질량함수의 곱으로 나타내질때.

- **확률표본(random sample)** : **iid 확률변수들의 집합**. 즉, 독립적이고, 동일한 분포를 이루는 확률변수 $$X_1,..,X_n$$을 **크기n의 '하나의' 확률표본**이라 부른다.

  > 즉, 확률표본, 혹은 r.s라는 말을 쓴 순간 **iid가 자동 내포** 된다는 것을 상기!

- **통계량 (a statistic)** : 확률표본 ($$X_1,..,X_n$$)의 '함수'. ex) $$\bar X, Median$$

  - iid확률변수들의 함수이기에, 통계량도 자연스레 확률변수이다.

- **표본분포 (sampling distribution)** : '통계량'의 확률분포. 

  > but 밝혀진 표본분포는 거의 없다. sample mean에 대해서만 좀 있음.

------

### Describing prob dist func

평균, 분산, 표준편차. 간단한 부분은 지면상 생략하겠다. 기억할 만한 부분만 적음.

확률분포의 특성에 대해서, 대표적으로 1차moment, 2차 moment가 있다.

1차 moment=평균=$$E(x)=\sum_{\forall x} x^1f(x)$$. 무게중심이 된다. 

2차 moment는 $$E(X^2)=\sum_{\forall x} x^2f(x)$$이지만, 평균을 중심으로 한 2차 moment는 분산.

즉, **평균,분산 등은** 확률분포를 **온전하게** 알아야 구할 수 있다.

왜 표준편차를 굳이 정의하느냐? => 분산이 제곱텀이기에, 원데이터와 unit(scale)을 맞춰주려고.



공분산 : 결합확률분포에 대한건 특성치. **joint pdf를 모르면 얻을 수 없다.**

$$\because Cov(X,Y)=E[(x-\mu_x)(y-\mu_y)]=E(XY)-\mu_x\mu_y$$

여기서 $$E(XY)=\sum_\forall x\sum \forall yf_{XY}(xy)$$이므로 **결합확률 분포를 알아야만** 구할 있는 특성치가 COV.

+, Cov는 X와 Y의 **'선형적강도'**이다. 즉, 상당히 제한적인 측도.

**Correlation** : 코스슈바르츠 부등식에 의해 -1에서 1까지로 bound되있다는걸 증명가능하다.

**코시슈바르츠 부등식** : 

​	$$[E(XY)]^2\le E(X^2)E(Y^2)$$

​	간단 proof.

​		$$E(X^2)\ge0, \forall X.$$

​		$$\therefore E[(ax-y)^2]\ge0$$

​		$$a^2E(x^2)-2aE(xy)+E(y^2)\ge0$$. 이걸 a에 대한 2차부등식으로 볼 수 있다. 이를 판별식으로

​		$$D=E(xy)-E(x^2)E(y^2)\le 0$$...CS부등식 증명 끝.

------

### 여러가지 대표적 분포들

**버놀리** : 결과값이 True, False의 두가지로 나뉘어질 수 있는 random variable의 분포

- $$X\sim ber(p)$$
- $$f(x)=p^x(1-p)^{1-x},x=0,1$$ 
- $$E(x)=p, Var(x)=p(1-p)$$

**이항분포** : n개의 버놀리r.v들의 합. 총n개의 버놀리 r.v중 True가 몇개인지를 나타내는 새로운 변수 X에 대한 분포

- $$X\sim bin(n,p)$$
- $$f(x)=_nC_xp^x(1-p)^{n-x}, x=0,1,..,n$$
- $$E(x)=np, Var(x)=np(1-p)$$

**포아송** : 포아송 분포는 binomial dist의 극한분포로써 처음으로 관찰되었다. 이항분포에서 n은 매우 커지고, p는 매우 작은 경우의 분포(예를들면 교통사고 처럼, 확률은 매우 낮지만 시행횟수, 즉 이동차량이 매우 많은 경우를 나타내는 분포)

- $$X\sim pois(\lambda)$$
- $$f(x)=\frac{e^{-\lambda}\lambda^x}{x!}$$
- $$E(x)=\lambda, Var(X)=\lambda$$

**카이제곱** : derived from $$Z$$(표준정규분포).

- $$Z\sim N(0,1)$$, then $$Z^2\sim \chi^2(1)$$

- Let $$Z_1,..,Z_n$$ indep. 

  $$Z_i\sim N(0,1), \forall i$$

  then $$\sum_{i=1}^nZ_i^2\sim \chi^2(n)$$.

  > 즉, Normal을 따르는 r.v. Z_i들의 제곱합 $$\sum_{i=1}^nZ_i^2$$ 역시 r.v.이 r.v.의 확률분포가 $$\chi^2(n)$$라는것.

- $$E(X)=n,V(X)=2n$$

- Chisq의 가법성:

  - 1) $$X_1\sim\chi^2(n_1)$$

  - 2) $$X_2\sim\chi^2(n_2)$$

  - 3) $$X_1 , X_2$$ are indep

    =>$$X_1+X_2\sim\chi^2(n_1+n_2)$$. 

  > 이 가법성은 이항분포, 포아송 분포 역시 만족한다.
  >
  > 또한 뒤에서 설명하지만 chisq는 gamma분포의 한 형태로 볼수도 있다.

**t-distn(티 분포)** : N에서 파생되는 애들중 하나.

- def : 

  - $$Z\sim N(0,1)$$

  - $$X_n\sim\chi^2(n)$$

  - $$Z,X_n$$ are indep

    =>$$\frac{Z}{\sqrt{X_n^2/n}}\sim t(n)$$, 

    즉 chisq따르는 rv를 그의 분포의 자유도로 나눠준 애가 분모에 들간다. 후에 보지만 이놈이 기막히게 들어가서 N을 따르는 샘플에서의 검정등에 t-dist로 귀결이 된다.

- $$E(X)=1,V(X)=\frac{n}{n-2}\ge1$$, 분산이 큰것은 꼬리가 N보다 두꺼운것과도 상통.

**F-distn(에프 분포)** : chisq를 따르는 두 r.v들의 분수형태. ANOVA에 사용된다!

- def :

  - $$X\sim\chi^2(n)$$

  - $$Y\sim\chi^2(m)$$

  - $$X,Y$$ are indep. (즉 n개의 지들끼리 indep한 $$Z_i$$와, m개의 지들끼리indep한 $$Z_j$$가, n과 m 서로서로의 $$Z_i,Z_j$$와도 indep함.)

    =>$$\frac{X/n}{Y/m}\sim F(n,m)$$

- if $$X\sim t(n)$$, then $$X^2\sim F(1,n)$$, 왜냐면 분자에 Z가 있으니까, (Z랑 분모의 rv랑도 by def로 indep니까)

**지수분포(exponential distn)** : 생존분석의 대표적이고 기본적인 분포로, 무기억성과 failure rate가 constant라는 특성이 있다.

- $$X\sim exp(\lambda)$$
- $$f(x)=\lambda e^{-\lambda x}$$
- $$E(x)=\frac{1}{\lambda}, Var(x)=\frac{1}{\lambda^2}$$

**감마분포** : non_negative r.v를 모델링할때 쓰이는 분포로, 다양한 형태를 취할 수 있다. 또, expo distn과 chisq distn을 포함하는 포괄적 분포이다

- $$X\sim gamma(\alpha,\beta)$$
- $$f(x)=\frac{\beta^\alpha}{\Gamma(\alpha)}x^{\alpha-1}e^{-\beta x}$$
- $$E(x)=\frac{\alpha}{\beta},Var(x)=\frac{\alpha}{\beta^2}$$
- $$exp(\lambda)\equiv gamma(1,\frac{1}{\lambda})$$
- $$\chi^2(p)\equiv gamma(\frac{p}{2},\frac{1}{2})$$

**베타분포** : x가 존재가능한 공간이 [0,1]일때 자주 사용되는 분포로, 역시 다양한 형태를 취할 수 있다.

- $$X\sim beta(\alpha,\beta)$$
- $$f(x)=\frac{\Gamma(\alpha+\beta)}{\Gamma(\alpha)\Gamma(\beta)}x^{\alpha-1}(1-x)^{\beta-1}$$
- $$E(x)=\frac{\alpha}{\alpha+\beta},Var(x)=\frac{\alpha\beta}{(\alpha+\beta)^2(\alpha+\beta+1)}$$

**음이항분포(negative binomial distn)** : 버놀리r.v와 관련된 또다른 분포. 성공확률 p 의 사건에서 r번의 성공을 하기 위해 필요한 시도횟수x에 대한 분포이다. 

- $$X\sim neg\_bin(r,p)$$
- $$f(x)=\begin{pmatrix}  x+r-1 \\ r-1  \end{pmatrix}(1-p)^xp^r,x=0,1,2..$$
- $$E(x)=\frac{r(1-p)}{p}, Var(x)=\frac{r(1-p)}{p^2}$$

덧. 같은 분포이더라도 $$\beta$$를 $$1/\beta$$로 설정한다던지로 인해 형태가 약간 달라질 수 있다. 이런 파라미터의 사용에 대해서 통일이 되어있지 않다.

막간상식 : 왜 자연현상의 많은 것이 N비슷?(ex키)

=>지금의 자연현상에 영향을 준 요인들은 오래전부터의 유전적 요인들의 가중평균.(ex 증조부의 키,할부지의 키,..) n은 거의 inf에 가까움. 이는 확장된 CLT에 의해 N에 근사하게 됨.

------

### Fundamental theorem of Normal distn

Let $$X_i\sim N(\mu,\sigma^2), \forall i$$, $$X_i$$'s are indep, 즉, iid X들이 다 N을 따를때, 다음의 **3가지 성질을** 만족.

1. $$\bar X\sim N(\mu,\frac{\sigma^2}{n})$$

2. $$\frac{(n-1)S^2}{\sigma^2}\sim\chi^2(n-1)$$, 이는 $$\frac{\sum(x_i-\bar x)}{\sigma^2}\sim\chi^2(n-1)$$와 같은말.

   > proof는 공책에. 증명에 아래의 3번 가정도 필요함


1. $$S^2, \bar X$$ are indep.

여기에서 variance를 sample variance로 대체한 t-dist가 도출됨
$$
\frac{\bar X-\mu}{S/\sqrt{n}}\sim t(n-1)
$$
$$\because T=\frac{Z}{\sqrt{Y/df}}$$, 

here $$Z=\frac{\bar X-\mu}{\sigma/\sqrt{n}}\sim N(0,1)$$, $$Y=\frac{(n-1)S^2}{\sigma^2}\sim \chi^2(n-1)$$, $$Z,Y$$ are indep.

> 2번 공식에 대한 proof. (수통에서 가져옴 66p)
>
> <img width="472" alt="funda_thm_proof" src="https://user-images.githubusercontent.com/31824102/60090557-b848dd80-977d-11e9-9b73-ab0e1caf30be.PNG">
>
> N을 따르는 n개의 iid data를 cov=0인 multivariate Normal로 봐서, $$\bar X$$와 $$S^2$$의 구성원간에 cov가 0임을 밝혔다.